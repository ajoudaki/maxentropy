{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f6c10d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import decomposition\n",
    "from sklearn import manifold\n",
    "import tqdm as tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import copy\n",
    "import random\n",
    "import time\n",
    "\n",
    "\n",
    "def calculate_accuracy(y_pred, y):\n",
    "    top_pred = y_pred.argmax(1, keepdim=True)\n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, device):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for (x, y) in tqdm.tqdm(iterator, desc=\"Training\", leave=False):\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = y.type(torch.LongTensor)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = model(x)\n",
    "\n",
    "        loss = criterion(y_pred, y)\n",
    "\n",
    "        acc = calculate_accuracy(y_pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "\n",
    "def evaluate(model, iterator, criterion, device):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.eval()\n",
    "    num_classes = dict()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for (x, y) in tqdm.tqdm(iterator, desc=\"Evaluating\", leave=False):\n",
    "\n",
    "            x = x.to(device)\n",
    "            y = y.type(torch.LongTensor)\n",
    "            y = y.to(device)\n",
    "\n",
    "\n",
    "            y_pred = model(x)\n",
    "            top_pred = y_pred.argmax(1).cpu().data.numpy()\n",
    "            for c in top_pred:\n",
    "                if c not in num_classes:\n",
    "                    num_classes[c] = 1\n",
    "                else:\n",
    "                    num_classes[c] += 1\n",
    "\n",
    "            loss = criterion(y_pred, y)\n",
    "\n",
    "            acc = calculate_accuracy(y_pred, y)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator), num_classes\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "def plot_images(images):\n",
    "\n",
    "    n_images = len(images)\n",
    "\n",
    "    rows = int(np.sqrt(n_images))\n",
    "    cols = int(np.sqrt(n_images))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    for i in range(rows*cols):\n",
    "        ax = fig.add_subplot(rows, cols, i+1)\n",
    "        ax.imshow(images[i].view(28, 28).cpu().numpy(), cmap='bone')\n",
    "        ax.axis('off')\n",
    "\n",
    "    \n",
    "def show_layers(Hidden, Num=None,subplot=True,title=False,save_path=None):\n",
    "    if not Num:\n",
    "        Num = len(Hidden)\n",
    "    inds = np.linspace(0,len(Hidden)-1,Num).astype(np.int32)\n",
    "    Hidden = [Hidden[i] for i in inds]\n",
    "    if subplot:\n",
    "        fig = plt.figure(figsize=(2*Num,2))\n",
    "    for Hi,(l,H) in enumerate(zip(inds,Hidden)):\n",
    "        while H.shape[0]==1:\n",
    "            H = H[0]\n",
    "        # H = H.data.numpy()\n",
    "        if subplot:\n",
    "            ax = fig.add_subplot(1,Num,Hi+1)\n",
    "        else:\n",
    "            plt.clf()\n",
    "            ax = plt.gca()\n",
    "        \n",
    "        ax.scatter(H[0],H[1],2)\n",
    "        if title:\n",
    "            ax.set_title(f'Layer = {Hi+1}')\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "703e45ce-3b4a-4dc5-871e-536215b61d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activ(torch.nn.Module):\n",
    "    def __init__(self, n_feature, activ):\n",
    "        super().__init__()\n",
    "        self.activ = activ\n",
    "        self.lin  = torch.nn.Parameter(torch.randn((6,n_feature)))\n",
    "\n",
    "    def forward(self, h):\n",
    "        # if self.activ=='relu':\n",
    "        #     return F.relu(h)\n",
    "        # if self.actv=='tanh':\n",
    "        #     return torch.tanh(h)\n",
    "        h2 = 0\n",
    "        if 'relu' in self.activ:\n",
    "            h2 += F.relu(h*self.lin[1]-self.lin[0]) \n",
    "        if 'tanh' in self.activ:\n",
    "            h2 += torch.tanh(h*self.lin[3]-self.lin[2]) \n",
    "        return h2\n",
    "        # h2 = .0 * h\n",
    "        # h2 += F.relu(self.lin[0]+self.lin[1]*h)*self.lin[2] \n",
    "        # h2 += torch.tanh(h*self.lin[4])*self.lin[3]\n",
    "        # return h2\n",
    "    \n",
    "\n",
    "class MyMLP(nn.Module):\n",
    "    def __init__(self, D, L, res, activ, norm, D_in, D_out, A, H, device):\n",
    "        super().__init__()\n",
    "        # assert(activ in ['lin', 'relu','tanh'])\n",
    "        assert(norm in ['', 'LN','BN1','BN2'])\n",
    "        self.A = A\n",
    "        self.H = H\n",
    "        self.norm = norm\n",
    "        self.activ = activ\n",
    "        self.fcs = [nn.Linear(D, D).to(device) for l in range(L)]\n",
    "        self.fcs[0] = nn.Linear(D_in,D).to(device)\n",
    "        self.fcs[-1] = nn.Linear(D,D_out).to(device)\n",
    "        self.acts = [Activ(D,activ).to(device) for l in range(L+1)]\n",
    "        self.acts[0] = Activ(D_in,activ).to(device)\n",
    "        self.attk = [nn.Linear(D, A).to(device) for l in range(L)]\n",
    "        self.attk[0] = nn.Linear(D_in,A).to(device)\n",
    "        self.attv = [nn.Linear(A, D).to(device) for l in range(L)]\n",
    "        self.attv[-1] = nn.Linear(A, D_out).to(device)\n",
    "        self.lin  = [(nn.Linear(D, D).to(device),nn.Linear(D, D).to(device)) for l in range(L)]\n",
    "        self.lin[-1] = (nn.Linear(D_out, D_out).to(device),nn.Linear(D_out, D_out).to(device))\n",
    "        \n",
    "        for li,fc in enumerate(self.fcs):\n",
    "            self.add_module(\"attk_\"+str(li), self.attk[li])\n",
    "            self.add_module(\"attv_\"+str(li), self.attv[li])\n",
    "            self.add_module(\"lin0_\"+str(li), self.lin[li][0])\n",
    "            self.add_module(\"lin1_\"+str(li), self.lin[li][1])\n",
    "            if li==len(self.fcs)-1:\n",
    "                self.add_module(\"fc_\"+str(li), fc)\n",
    "            self.add_module(\"act_\"+str(li), self.acts[li])\n",
    "        self.L = L\n",
    "        self.D = D\n",
    "        self.res = res\n",
    "        self.sm = nn.Softmax(dim=2)\n",
    "    \n",
    "    def normalize(self, h):\n",
    "        if self.norm=='LN':\n",
    "            # h = h - h.mean(1,keepdim=True)\n",
    "            h = h / torch.norm(h,dim=1,keepdim=True)\n",
    "        if self.norm=='BN2':\n",
    "            h = h - h.mean(0,keepdim=True)\n",
    "            h = h / torch.norm(h,dim=0,keepdim=True)\n",
    "        if self.norm=='BN1':\n",
    "            h = h / torch.norm(h,dim=0,keepdim=True)\n",
    "        return h \n",
    "        \n",
    "    def layer_update(self, l,h):\n",
    "        h2 = h\n",
    "        if l>0:\n",
    "            h2 = self.normalize(h2)\n",
    "        # h2 = self.acts[l](h2)\n",
    "        A = self.attk[l](h2)\n",
    "        A = A.view(A.shape[0],self.H,-1)\n",
    "        A = self.sm(A)\n",
    "        A = A.view(A.shape[0],-1)\n",
    "        V = self.attv[l](A) / np.sqrt(self.A)\n",
    "        V = self.lin[l][0](V)\n",
    "        V = torch.tanh(V)\n",
    "        V = self.lin[l][1](V)\n",
    "        h2 = self.fcs[l](h2)\n",
    "        h2 += V\n",
    "        \n",
    "        if l==self.L-1:\n",
    "            h2 = torch.softmax(h2,1)\n",
    "        return h2\n",
    "\n",
    "\n",
    "    def full_forward(self, h):\n",
    "        h = h.view(h.shape[0],-1) # flatten images to vectors\n",
    "        H = [h.cpu().data.numpy()]\n",
    "        for l in range(self.L):\n",
    "            h = self.layer_update(l,h)\n",
    "            H.append(h.cpu().data.numpy())\n",
    "        return H\n",
    "    \n",
    "    def forward(self, h):\n",
    "        h = h.view(h.shape[0],-1) #  # flatten images to vectors\n",
    "        for l in range(self.L):\n",
    "            h = self.layer_update(l,h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "77c2ef65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2\tTrain Loss: 2.08963\tTrain Acc: 0.3674712276367275\tVal. Loss: 2.07435\t Val. Acc: 0.38202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3\tTrain Loss: 2.05837\tTrain Acc: 0.39801790281329924\tVal. Loss: 2.04892\t Val. Acc: 0.40951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4\tTrain Loss: 2.03222\tTrain Acc: 0.4248401534831737\tVal. Loss: 2.03462\t Val. Acc: 0.42128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5\tTrain Loss: 2.01083\tTrain Acc: 0.44804187984112887\tVal. Loss: 2.01123\t Val. Acc: 0.44343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6\tTrain Loss: 1.99439\tTrain Acc: 0.46482177113023254\tVal. Loss: 2.00983\t Val. Acc: 0.44432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7\tTrain Loss: 1.98226\tTrain Acc: 0.4757792519029144\tVal. Loss: 2.00071\t Val. Acc: 0.45570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8\tTrain Loss: 1.96914\tTrain Acc: 0.4906369885215369\tVal. Loss: 1.99519\t Val. Acc: 0.46015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9\tTrain Loss: 1.95486\tTrain Acc: 0.5050711317745316\tVal. Loss: 1.99047\t Val. Acc: 0.46351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10\tTrain Loss: 1.94317\tTrain Acc: 0.5170915921020995\tVal. Loss: 1.98075\t Val. Acc: 0.47449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11\tTrain Loss: 1.93060\tTrain Acc: 0.5302469629765777\tVal. Loss: 1.98167\t Val. Acc: 0.47498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12\tTrain Loss: 1.92120\tTrain Acc: 0.5389146419132457\tVal. Loss: 1.97552\t Val. Acc: 0.48151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13\tTrain Loss: 1.91070\tTrain Acc: 0.5506273977591863\tVal. Loss: 1.97313\t Val. Acc: 0.48230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14\tTrain Loss: 1.90267\tTrain Acc: 0.5587555945986677\tVal. Loss: 1.97676\t Val. Acc: 0.47903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15\tTrain Loss: 1.89491\tTrain Acc: 0.5666919757643014\tVal. Loss: 1.97346\t Val. Acc: 0.48170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16\tTrain Loss: 1.88521\tTrain Acc: 0.5763507034162731\tVal. Loss: 1.97231\t Val. Acc: 0.48438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17\tTrain Loss: 1.88026\tTrain Acc: 0.5814378197540713\tVal. Loss: 1.97389\t Val. Acc: 0.48250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18\tTrain Loss: 1.87397\tTrain Acc: 0.5866168478260869\tVal. Loss: 1.97011\t Val. Acc: 0.48764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19\tTrain Loss: 1.86779\tTrain Acc: 0.5938419117342175\tVal. Loss: 1.96830\t Val. Acc: 0.48794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20\tTrain Loss: 1.86072\tTrain Acc: 0.6012547953659312\tVal. Loss: 1.97382\t Val. Acc: 0.48428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21\tTrain Loss: 1.85610\tTrain Acc: 0.6055346867617439\tVal. Loss: 1.96594\t Val. Acc: 0.49308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22\tTrain Loss: 1.85180\tTrain Acc: 0.6095468350078749\tVal. Loss: 1.96316\t Val. Acc: 0.49466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23\tTrain Loss: 1.84767\tTrain Acc: 0.6141823848799977\tVal. Loss: 1.96502\t Val. Acc: 0.49199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24\tTrain Loss: 1.84174\tTrain Acc: 0.6198529412069589\tVal. Loss: 1.96203\t Val. Acc: 0.49545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25\tTrain Loss: 1.83959\tTrain Acc: 0.6215752876932968\tVal. Loss: 1.96579\t Val. Acc: 0.49189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26\tTrain Loss: 1.83584\tTrain Acc: 0.6258431906285493\tVal. Loss: 1.96431\t Val. Acc: 0.49140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27\tTrain Loss: 1.83221\tTrain Acc: 0.6288003517538691\tVal. Loss: 1.96589\t Val. Acc: 0.49278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28\tTrain Loss: 1.82582\tTrain Acc: 0.6355298913043478\tVal. Loss: 1.96486\t Val. Acc: 0.49347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29\tTrain Loss: 1.82418\tTrain Acc: 0.6365609015040385\tVal. Loss: 1.96541\t Val. Acc: 0.49130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30\tTrain Loss: 1.82092\tTrain Acc: 0.6407848465473146\tVal. Loss: 1.96574\t Val. Acc: 0.49150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31\tTrain Loss: 1.81931\tTrain Acc: 0.6416440217391305\tVal. Loss: 1.95960\t Val. Acc: 0.49891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32\tTrain Loss: 1.81305\tTrain Acc: 0.6481457800816393\tVal. Loss: 1.96505\t Val. Acc: 0.49387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33\tTrain Loss: 1.80934\tTrain Acc: 0.6518462275909951\tVal. Loss: 1.96208\t Val. Acc: 0.49535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34\tTrain Loss: 1.80610\tTrain Acc: 0.6551870205213347\tVal. Loss: 1.96080\t Val. Acc: 0.49753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35\tTrain Loss: 1.80390\tTrain Acc: 0.6570492327365729\tVal. Loss: 1.96217\t Val. Acc: 0.49555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36\tTrain Loss: 1.80304\tTrain Acc: 0.6580322890940224\tVal. Loss: 1.96280\t Val. Acc: 0.49466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37\tTrain Loss: 1.79714\tTrain Acc: 0.6643182545366799\tVal. Loss: 1.95897\t Val. Acc: 0.49990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38\tTrain Loss: 1.79891\tTrain Acc: 0.6618965792533992\tVal. Loss: 1.96064\t Val. Acc: 0.49753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39\tTrain Loss: 1.79705\tTrain Acc: 0.6638347186395884\tVal. Loss: 1.96522\t Val. Acc: 0.49159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40\tTrain Loss: 1.79327\tTrain Acc: 0.6673233696566824\tVal. Loss: 1.96212\t Val. Acc: 0.49604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41\tTrain Loss: 1.78955\tTrain Acc: 0.6717750959079284\tVal. Loss: 1.96402\t Val. Acc: 0.49446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42\tTrain Loss: 1.78817\tTrain Acc: 0.6731537723785166\tVal. Loss: 1.96180\t Val. Acc: 0.49693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43\tTrain Loss: 1.78785\tTrain Acc: 0.6733975384546362\tVal. Loss: 1.96307\t Val. Acc: 0.49515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44\tTrain Loss: 1.78405\tTrain Acc: 0.6770620204298697\tVal. Loss: 1.96253\t Val. Acc: 0.49565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45\tTrain Loss: 1.78331\tTrain Acc: 0.6776734335953013\tVal. Loss: 1.96063\t Val. Acc: 0.49624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46\tTrain Loss: 1.78105\tTrain Acc: 0.6800511509866056\tVal. Loss: 1.96154\t Val. Acc: 0.49703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47\tTrain Loss: 1.77840\tTrain Acc: 0.682308983467424\tVal. Loss: 1.95932\t Val. Acc: 0.49891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48\tTrain Loss: 1.77829\tTrain Acc: 0.6824608376568846\tVal. Loss: 1.96407\t Val. Acc: 0.49377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49\tTrain Loss: 1.77622\tTrain Acc: 0.6846427429667519\tVal. Loss: 1.96024\t Val. Acc: 0.49941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50\tTrain Loss: 1.77356\tTrain Acc: 0.6874560422604651\tVal. Loss: 1.96241\t Val. Acc: 0.49614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51\tTrain Loss: 1.76936\tTrain Acc: 0.6921795077640992\tVal. Loss: 1.95981\t Val. Acc: 0.49881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52\tTrain Loss: 1.77034\tTrain Acc: 0.6908527813908999\tVal. Loss: 1.95751\t Val. Acc: 0.50089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 53\tTrain Loss: 1.76802\tTrain Acc: 0.6927989131349432\tVal. Loss: 1.96275\t Val. Acc: 0.49515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54\tTrain Loss: 1.76774\tTrain Acc: 0.6930426790586213\tVal. Loss: 1.95970\t Val. Acc: 0.50020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 55\tTrain Loss: 1.76485\tTrain Acc: 0.6959798593655266\tVal. Loss: 1.96057\t Val. Acc: 0.49862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56\tTrain Loss: 1.76550\tTrain Acc: 0.6954763428024624\tVal. Loss: 1.95752\t Val. Acc: 0.50069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 57\tTrain Loss: 1.76380\tTrain Acc: 0.6966751919073217\tVal. Loss: 1.96058\t Val. Acc: 0.49842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 58\tTrain Loss: 1.76140\tTrain Acc: 0.6995004795091536\tVal. Loss: 1.95706\t Val. Acc: 0.50188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 59\tTrain Loss: 1.76094\tTrain Acc: 0.6999080882352942\tVal. Loss: 1.96090\t Val. Acc: 0.49812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60\tTrain Loss: 1.75647\tTrain Acc: 0.7050391624650687\tVal. Loss: 1.96157\t Val. Acc: 0.49703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 61\tTrain Loss: 1.75620\tTrain Acc: 0.7049672315492654\tVal. Loss: 1.95937\t Val. Acc: 0.49862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 62\tTrain Loss: 1.75523\tTrain Acc: 0.7059103261174449\tVal. Loss: 1.95796\t Val. Acc: 0.50138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 63\tTrain Loss: 1.75519\tTrain Acc: 0.7055626598465473\tVal. Loss: 1.96190\t Val. Acc: 0.49723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 64\tTrain Loss: 1.75335\tTrain Acc: 0.707408887498519\tVal. Loss: 1.95781\t Val. Acc: 0.50129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 65\tTrain Loss: 1.75105\tTrain Acc: 0.7097546356108487\tVal. Loss: 1.96278\t Val. Acc: 0.49595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66\tTrain Loss: 1.75029\tTrain Acc: 0.7106058184448105\tVal. Loss: 1.96186\t Val. Acc: 0.49723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 67\tTrain Loss: 1.74940\tTrain Acc: 0.711632832541795\tVal. Loss: 1.95827\t Val. Acc: 0.50049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 68\tTrain Loss: 1.74738\tTrain Acc: 0.7132153132992327\tVal. Loss: 1.96026\t Val. Acc: 0.49881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 69\tTrain Loss: 1.74727\tTrain Acc: 0.7132792520096235\tVal. Loss: 1.95541\t Val. Acc: 0.50405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 70\tTrain Loss: 1.74837\tTrain Acc: 0.7125519501888539\tVal. Loss: 1.95683\t Val. Acc: 0.50247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 71\tTrain Loss: 1.74619\tTrain Acc: 0.7143742007672634\tVal. Loss: 1.95812\t Val. Acc: 0.50049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 72\tTrain Loss: 1.74372\tTrain Acc: 0.717095588326759\tVal. Loss: 1.96051\t Val. Acc: 0.49852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73\tTrain Loss: 1.74434\tTrain Acc: 0.7166200447875215\tVal. Loss: 1.96067\t Val. Acc: 0.49852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 74\tTrain Loss: 1.73885\tTrain Acc: 0.721922954025171\tVal. Loss: 1.95629\t Val. Acc: 0.50297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 75\tTrain Loss: 1.74047\tTrain Acc: 0.7202485613810742\tVal. Loss: 1.96342\t Val. Acc: 0.49565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 76\tTrain Loss: 1.73947\tTrain Acc: 0.7216272378516624\tVal. Loss: 1.95862\t Val. Acc: 0.50089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 77\tTrain Loss: 1.73652\tTrain Acc: 0.7243326406954499\tVal. Loss: 1.95516\t Val. Acc: 0.50405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 78\tTrain Loss: 1.73642\tTrain Acc: 0.7245244565217391\tVal. Loss: 1.95885\t Val. Acc: 0.50010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 79\tTrain Loss: 1.73705\tTrain Acc: 0.7238451086956522\tVal. Loss: 1.95514\t Val. Acc: 0.50366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80\tTrain Loss: 1.73635\tTrain Acc: 0.7243726023322786\tVal. Loss: 1.95994\t Val. Acc: 0.49921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 81\tTrain Loss: 1.73259\tTrain Acc: 0.7283887468335574\tVal. Loss: 1.95736\t Val. Acc: 0.50129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 82\tTrain Loss: 1.73229\tTrain Acc: 0.7284486892888004\tVal. Loss: 1.95640\t Val. Acc: 0.50247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 83\tTrain Loss: 1.72946\tTrain Acc: 0.7314977621483376\tVal. Loss: 1.95763\t Val. Acc: 0.50040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 84\tTrain Loss: 1.73102\tTrain Acc: 0.7298833121119253\tVal. Loss: 1.96160\t Val. Acc: 0.49723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 85\tTrain Loss: 1.73011\tTrain Acc: 0.7307824489405698\tVal. Loss: 1.95901\t Val. Acc: 0.49980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 86\tTrain Loss: 1.72866\tTrain Acc: 0.7321771099744245\tVal. Loss: 1.95601\t Val. Acc: 0.50307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 87\tTrain Loss: 1.72944\tTrain Acc: 0.7314098465168263\tVal. Loss: 1.95442\t Val. Acc: 0.50415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 88\tTrain Loss: 1.72640\tTrain Acc: 0.7344669117342175\tVal. Loss: 1.96113\t Val. Acc: 0.49713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 89\tTrain Loss: 1.72596\tTrain Acc: 0.7350463554682329\tVal. Loss: 1.95286\t Val. Acc: 0.50653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90\tTrain Loss: 1.72156\tTrain Acc: 0.7393622122457265\tVal. Loss: 1.95481\t Val. Acc: 0.50455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 91\tTrain Loss: 1.72539\tTrain Acc: 0.7356937340153452\tVal. Loss: 1.95940\t Val. Acc: 0.49941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 92\tTrain Loss: 1.72169\tTrain Acc: 0.739338235324606\tVal. Loss: 1.95960\t Val. Acc: 0.49862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 93\tTrain Loss: 1.72187\tTrain Acc: 0.7388347187615416\tVal. Loss: 1.95521\t Val. Acc: 0.50405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 94\tTrain Loss: 1.72059\tTrain Acc: 0.7404371803373937\tVal. Loss: 1.95413\t Val. Acc: 0.50534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 95\tTrain Loss: 1.71900\tTrain Acc: 0.7418757992632249\tVal. Loss: 1.95468\t Val. Acc: 0.50425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 96\tTrain Loss: 1.71876\tTrain Acc: 0.7421994884605603\tVal. Loss: 1.95768\t Val. Acc: 0.50129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 97\tTrain Loss: 1.71961\tTrain Acc: 0.7412284207161125\tVal. Loss: 1.95586\t Val. Acc: 0.50257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 98\tTrain Loss: 1.71666\tTrain Acc: 0.7443254475703325\tVal. Loss: 1.96017\t Val. Acc: 0.49891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 99\tTrain Loss: 1.71946\tTrain Acc: 0.7415521100658895\tVal. Loss: 1.95613\t Val. Acc: 0.50287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100\tTrain Loss: 1.71683\tTrain Acc: 0.74418957809658\tVal. Loss: 1.95705\t Val. Acc: 0.50188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 101\tTrain Loss: 1.71680\tTrain Acc: 0.7441775894835782\tVal. Loss: 1.95522\t Val. Acc: 0.50376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 102\tTrain Loss: 1.71535\tTrain Acc: 0.7456202046645571\tVal. Loss: 1.95427\t Val. Acc: 0.50485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 103\tTrain Loss: 1.71263\tTrain Acc: 0.7478540600718134\tVal. Loss: 1.95664\t Val. Acc: 0.50257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 104\tTrain Loss: 1.71539\tTrain Acc: 0.7455163043173377\tVal. Loss: 1.95686\t Val. Acc: 0.50188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 105\tTrain Loss: 1.71151\tTrain Acc: 0.7494165601632784\tVal. Loss: 1.95305\t Val. Acc: 0.50702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 106\tTrain Loss: 1.71107\tTrain Acc: 0.7502437660761196\tVal. Loss: 1.95748\t Val. Acc: 0.50129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 107\tTrain Loss: 1.71125\tTrain Acc: 0.7494964834369356\tVal. Loss: 1.96463\t Val. Acc: 0.49308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 108\tTrain Loss: 1.71226\tTrain Acc: 0.7483535805321715\tVal. Loss: 1.96004\t Val. Acc: 0.49891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 109\tTrain Loss: 1.71012\tTrain Acc: 0.750559462915601\tVal. Loss: 1.95675\t Val. Acc: 0.50247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 110\tTrain Loss: 1.70699\tTrain Acc: 0.754028132961839\tVal. Loss: 1.96081\t Val. Acc: 0.49654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 111\tTrain Loss: 1.70736\tTrain Acc: 0.7536165281329923\tVal. Loss: 1.95796\t Val. Acc: 0.50089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 112\tTrain Loss: 1.70675\tTrain Acc: 0.754148017872325\tVal. Loss: 1.95250\t Val. Acc: 0.50771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 113\tTrain Loss: 1.70732\tTrain Acc: 0.7537563938618926\tVal. Loss: 1.95906\t Val. Acc: 0.50020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 114\tTrain Loss: 1.70657\tTrain Acc: 0.7541919757643014\tVal. Loss: 1.95405\t Val. Acc: 0.50613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 115\tTrain Loss: 1.70388\tTrain Acc: 0.7571771100658895\tVal. Loss: 1.95649\t Val. Acc: 0.50257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 116\tTrain Loss: 1.70746\tTrain Acc: 0.7533288043173377\tVal. Loss: 1.96187\t Val. Acc: 0.49693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 117\tTrain Loss: 1.70527\tTrain Acc: 0.755446771069256\tVal. Loss: 1.96071\t Val. Acc: 0.49812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 118\tTrain Loss: 1.70474\tTrain Acc: 0.7562140345268542\tVal. Loss: 1.95818\t Val. Acc: 0.50099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 119\tTrain Loss: 1.70477\tTrain Acc: 0.7561860613505859\tVal. Loss: 1.95814\t Val. Acc: 0.50089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 120\tTrain Loss: 1.70204\tTrain Acc: 0.759127237912639\tVal. Loss: 1.96023\t Val. Acc: 0.49832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 121\tTrain Loss: 1.70276\tTrain Acc: 0.7579084079893653\tVal. Loss: 1.95437\t Val. Acc: 0.50494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 122\tTrain Loss: 1.70052\tTrain Acc: 0.7603820332175936\tVal. Loss: 1.95860\t Val. Acc: 0.50069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 123\tTrain Loss: 1.69863\tTrain Acc: 0.7621443414932016\tVal. Loss: 1.96130\t Val. Acc: 0.49773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 124\tTrain Loss: 1.69881\tTrain Acc: 0.7619205562354964\tVal. Loss: 1.96146\t Val. Acc: 0.49753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 125\tTrain Loss: 1.69951\tTrain Acc: 0.7613131394776542\tVal. Loss: 1.95854\t Val. Acc: 0.50059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 126\tTrain Loss: 1.69890\tTrain Acc: 0.7618845908538155\tVal. Loss: 1.95422\t Val. Acc: 0.50544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 127\tTrain Loss: 1.69920\tTrain Acc: 0.7616528133906977\tVal. Loss: 1.95832\t Val. Acc: 0.50059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 128\tTrain Loss: 1.69851\tTrain Acc: 0.7624320653088562\tVal. Loss: 1.96173\t Val. Acc: 0.49674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 129\tTrain Loss: 1.69733\tTrain Acc: 0.7636029412374472\tVal. Loss: 1.95853\t Val. Acc: 0.50030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 130\tTrain Loss: 1.69511\tTrain Acc: 0.7656729539946827\tVal. Loss: 1.96273\t Val. Acc: 0.49664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                               \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [40]\u001b[0m, in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters()) \u001b[38;5;66;03m# optim.SGD(model.parameters(),lr=1e-3)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[0;32m---> 33\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     valid_loss, valid_acc, freq \u001b[38;5;241m=\u001b[39m evaluate(model, test_iterator, criterion, device)\n\u001b[1;32m     35\u001b[0m     df\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;28mlen\u001b[39m(df),:] \u001b[38;5;241m=\u001b[39m (epoch, BATCH_SIZE,WIDTH,LAYERS, NORM,ACTIVATION,train_acc, valid_acc, train_loss, valid_loss)\n",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, device)\u001b[0m\n\u001b[1;32m     35\u001b[0m epoch_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     37\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (x, y) \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(iterator, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     41\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     42\u001b[0m     y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mLongTensor)\n",
      "File \u001b[0;32m~/Codes/maxentropy/venv/lib/python3.8/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/Codes/maxentropy/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:652\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 652\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    655\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    656\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/Codes/maxentropy/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:692\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    691\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 692\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    694\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/Codes/maxentropy/venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Codes/maxentropy/venv/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:175\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    172\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [default_collate(samples) \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Codes/maxentropy/venv/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:175\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    172\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mdefault_collate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Codes/maxentropy/venv/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:149\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np_str_obj_array_pattern\u001b[38;5;241m.\u001b[39msearch(elem\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mstr) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    147\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[38;5;241m.\u001b[39mformat(elem\u001b[38;5;241m.\u001b[39mdtype))\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdefault_collate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m elem\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m ():  \u001b[38;5;66;03m# scalars\u001b[39;00m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mas_tensor(batch)\n",
      "File \u001b[0;32m~/Codes/maxentropy/venv/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py:141\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    139\u001b[0m         storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mstorage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    140\u001b[0m         out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[0;32m--> 141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstr_\u001b[39m\u001b[38;5;124m'\u001b[39m \\\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstring_\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mndarray\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m elem_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmemmap\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;66;03m# array of string classes and object\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 1000\n",
    "\n",
    "WIDTH = 1000\n",
    "LAYERS = 5\n",
    "\n",
    "HEADS = 20\n",
    "ATT = HEADS * 20\n",
    "assert(ATT % HEADS == 0)\n",
    "\n",
    "RES = .0\n",
    "BATCH_SIZE = 2**7\n",
    "ACTIVATION = 'relu,tanh'\n",
    "NORM = 'BN2'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = 'cpu'\n",
    "\n",
    "df = pd.DataFrame(columns=['epoch','bath_size','width','layers','normalization','activation','train_acc','val_acc','train_loss','val_loss',])\n",
    "\n",
    "\n",
    "train_iterator = data.DataLoader(train_data,batch_size=BATCH_SIZE)\n",
    "test_iterator = data.DataLoader(test_data,batch_size=BATCH_SIZE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "model = MyMLP(L=LAYERS,D=WIDTH,res=RES,activ=ACTIVATION, norm=NORM, D_in=D_IN, D_out=num_classes, A = ATT, H=HEADS,device=device)\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "optimizer = optim.Adam(model.parameters()) # optim.SGD(model.parameters(),lr=1e-3)\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion, device)\n",
    "    valid_loss, valid_acc, freq = evaluate(model, test_iterator, criterion, device)\n",
    "    df.loc[len(df),:] = (epoch, BATCH_SIZE,WIDTH,LAYERS, NORM,ACTIVATION,train_acc, valid_acc, train_loss, valid_loss)\n",
    "    if epoch==0:\n",
    "        continue\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'tut1-model.pt')\n",
    "\n",
    "    print(f'Epoch: {epoch+1}\\tTrain Loss: {train_loss:.5f}\\tTrain Acc: {train_acc}\\tVal. Loss: {valid_loss:.5f}\\t Val. Acc: {valid_acc:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b2f6e444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculated mean: 0.13066047430038452\n",
      "Calculated std: 0.30810779333114624\n",
      "Number of training examples: 60000\n",
      "Number of testing examples: 10000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 25 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ROOT = '.data'\n",
    "train_data = datasets.MNIST(root=ROOT,\n",
    "                            train=True,\n",
    "                            download=True)\n",
    "\n",
    "mean = train_data.data.float().mean() / 255\n",
    "std = train_data.data.float().std() / 255\n",
    "print(f'Calculated mean: {mean}')\n",
    "print(f'Calculated std: {std}')\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "                            transforms.RandomRotation(5, fill=(0,)),\n",
    "                            transforms.RandomCrop(28, padding=2),\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Normalize(mean=[mean], std=[std])\n",
    "                                      ])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean=[mean], std=[std])\n",
    "                                     ])\n",
    "\n",
    "train_data = datasets.MNIST(root=ROOT,\n",
    "                            train=True,\n",
    "                            download=True,\n",
    "                            transform=train_transforms)\n",
    "\n",
    "test_data = datasets.MNIST(root=ROOT,\n",
    "                           train=False,\n",
    "                           download=True,\n",
    "                           transform=test_transforms)\n",
    "\n",
    "Classes = list(range(10))\n",
    "# Classes = [0,1]\n",
    "train_data = [(x,y) for x,y in train_data if y in Classes]\n",
    "test_data = [(x,y) for x,y in test_data if y in Classes]\n",
    "\n",
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')\n",
    "\n",
    "N_IMAGES = 25\n",
    "\n",
    "images = [image for image, label in [test_data[i] for i in range(N_IMAGES)]]\n",
    "\n",
    "D_IN = 28*28\n",
    "\n",
    "plot_images(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "842d7e60-7768-4cfd-a803-22d7407dbce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "trainset = torchvision.datasets.CIFAR100(root='.data',train=True,download=True)\n",
    "testset = torchvision.datasets.CIFAR100(root='.data',train=False,download=True)\n",
    "\n",
    "train_data = [(np.array(x,np.float32),np.float32(y)) for x,y in trainset]\n",
    "test_data = [(np.array(x,np.float32),np.float32(y)) for x,y in testset]\n",
    "\n",
    "num_classes = 100\n",
    "\n",
    "D_IN = 32*32*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "796ac1dd-86bd-4dbc-acc1-ab847615ddf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "trainset = torchvision.datasets.CIFAR10(root='.data',train=True,download=True)\n",
    "testset = torchvision.datasets.CIFAR10(root='.data',train=False,download=True)\n",
    "\n",
    "train_data = [(np.array(x,np.float32),np.float32(y)) for x,y in trainset]\n",
    "test_data = [(np.array(x,np.float32),np.float32(y)) for x,y in testset]\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "D_IN = 32*32*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5af930a7-fa14-443c-93ff-4e8bd752ec77",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data[0][0]\n",
    "N = len(X.flatten())\n",
    "Ind = np.array(np.unravel_index(range(N),shape=X.shape))\n",
    "def get_X2(X):\n",
    "    X2 = np.zeros((4,N))\n",
    "    X2[:3,:] = Ind\n",
    "    X2[3,:] = X.flatten()\n",
    "    return np.array(X2.flatten(),np.float32)\n",
    "train_data = [(get_X2(x),y) for x,y in train_data]\n",
    "test_data = [(get_X2(x),y) for x,y in test_data]\n",
    "\n",
    "D_IN = len(train_data[0][0].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9743def4-74df-47c6-bd3e-7a91a580ceee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
